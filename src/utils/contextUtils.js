/**
 * Utilities for handling file context for AI processing
 */

/**
 * Extracts relevant content from standardized files to use as context
 * @param {Array} files - Array of standardized file objects
 * @param {number} maxTokens - Optional max token limit
 * @returns {string} - Formatted context string
 */
export const buildContextFromFiles = (files, maxTokens = 4000) => {
    if (!files || !files.length) return '';
    
    let context = '### FILES INCLUDED IN CONTEXT:\n\n';
    
    files.forEach((file, index) => {
      // Add file metadata
      context += `## FILE ${index + 1}: ${file.name}\n`;
      context += `Format: ${file.jsonData?.format || 'unknown'}\n`;
      
      // Extract content based on file type
      if (file.jsonData?.format === 'markdown') {
        // For markdown files, include the raw content
        context += `\nContent:\n${file.jsonData.content}\n\n`;
      } 
      else if (file.jsonData?.format === 'csv' || file.jsonData?.format === 'excel') {
        // For tabular data, summarize the structure and include a sample
        const data = file.jsonData.data || 
                   (file.jsonData.sheets && Object.values(file.jsonData.sheets)[0]?.data);
        
        if (data && data.length) {
          const headers = Object.keys(data[0]).join(', ');
          context += `\nHeaders: ${headers}\n`;
          context += `Rows: ${data.length}\n`;
          
          // Include first 3 rows as a sample
          context += '\nSample data:\n';
          data.slice(0, 3).forEach((row, i) => {
            context += `Row ${i+1}: ${JSON.stringify(row)}\n`;
          });
          context += '\n';
        }
      }
      else if (file.jsonData?.format === 'json') {
        // For JSON files, include a representation of the structure
        context += `\nJSON Structure: ${JSON.stringify(file.jsonData.analysis)}\n`;
        
        // If the data is an array, show the first item
        if (Array.isArray(file.jsonData.data)) {
          context += `\nFirst item sample: ${JSON.stringify(file.jsonData.data[0], null, 2)}\n\n`;
        } 
        // Otherwise show the top-level keys
        else if (typeof file.jsonData.data === 'object' && file.jsonData.data !== null) {
          context += `\nTop-level keys: ${Object.keys(file.jsonData.data).join(', ')}\n\n`;
        }
      }
      
      context += '---\n\n';
    });
    
    // Add instructions for the AI
    context += `
  ### INSTRUCTIONS:
  - Reference the above files in your response when appropriate
  - If asked about file content, respond with information from the files
  - If the user asks for specific analysis of these files, perform the analysis using the provided data
  `;
  
    return context;
  };
  
  /**
   * Estimates token count in a string (very rough approximation)
   * @param {string} text - Input text
   * @returns {number} - Estimated token count
   */
  export const estimateTokenCount = (text) => {
    if (!text) return 0;
    // Very rough estimation - 4 chars per token on average
    return Math.ceil(text.length / 4);
  };
  
  /**
   * Prepare a message for the AI API that includes file context
   * @param {string} userPrompt - User's question/prompt
   * @param {Array} selectedFiles - Files to include as context
   * @param {string} defaultContext - Default context from settings
   * @returns {Object} - Formatted message for the API
   */
  export const preparePromptWithContext = (userPrompt, selectedFiles, defaultContext = '') => {
    const fileContext = buildContextFromFiles(selectedFiles);
    
    return {
      messages: [
        {
          role: 'system',
          content: `You are ASTER AI, an assistant specialized in analyzing documents and data.
  ${defaultContext ? `\nUser-provided context:\n${defaultContext}\n` : ''}
  ${fileContext ? `\nContext from selected files:\n${fileContext}` : ''}
          `
        },
        {
          role: 'user',
          content: userPrompt
        }
      ]
    };
  };
  
  /**
   * Simulates an AI response for development (when no API key is available)
   * @param {string} prompt - User's prompt
   * @param {Array} files - Selected files
   * @returns {string} - Simulated response
   */
  export const simulateAIResponse = async (prompt, files) => {
    // Simulate network latency
    await new Promise(resolve => setTimeout(resolve, 1000));
    
    let response = `This is a simulated AI response. In production, this would be generated by the OpenAI API.\n\n`;
    
    if (files && files.length > 0) {
      response += `I see you've included ${files.length} file(s) in your query:\n`;
      files.forEach(file => {
        response += `- ${file.name} (${file.jsonData?.format || 'unknown format'})\n`;
      });
      response += `\n`;
    }
    
    response += `Your query was: "${prompt}"\n\n`;
    
    if (prompt.toLowerCase().includes('summary') || prompt.toLowerCase().includes('analyze')) {
      response += `Based on the files you've provided, I would perform an analysis considering the file formats and content.`;
    } else if (prompt.toLowerCase().includes('extract') || prompt.toLowerCase().includes('find')) {
      response += `I would search through the provided files to extract the specific information you're looking for.`;
    } else {
      response += `I would provide a helpful response using both my general knowledge and the specific context from your files.`;
    }
    
    return response;
  };
  
  export default {
    buildContextFromFiles,
    estimateTokenCount,
    preparePromptWithContext,
    simulateAIResponse
  };